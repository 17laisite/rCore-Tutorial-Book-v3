锁机制
=========================================

本节导读
-----------------------------------------

到目前为止，我们已经实现了进程和线程，也能够理解在一个时间段内，会有多个线程在执行，这就是并发。而且，由于线程的引入，多个线程可以共享进程中的全局数据。如果多个线程都想读和更新全局数据，那么谁先更新取决于操作系统内核的抢占式调度和分派策略。在一般情况下，每个线程都有可能先执行，且可能由于中断等因素，随时被操作系统打断其执行，而切换到另外一个线程运行，形成在一段时间内，多个线程交替执行的现象。如果没有一些保障机制（比如互斥、同步等），那么这些对共享数据进行读写的交替执行的线程，其期望的共享数据的正确结果可能无法达到。

所以，我们需要研究一种保障机制 -- 锁 ，确保无论操作系统如何抢占线程，调度和切换线程的执行，都可以保证对拥有锁的线程，可以独占地对共享数据进行读写，从而能够得到正确的共享数据结果。这种机制的能力来自于处理器的指令、操作系统系统调用的基本支持，从而能够保证线程间互斥地读写共享数据。下面各个小节将从为什么需要锁、锁的基本思路、锁的不同实现方式等逐步展开讲解。

为什么需要锁
-----------------------------------------

上一小节已经提到，没有保障机制的多个线程，在对共享数据进行读写的过程中，可能得不到预期的结果。这需要有一个简单的例子来看看：

.. code-block:: c
    :linenos:
    :emphasize-lines: 4

	// 线程的入口函数
	int a=0;
	void f() {
	  a=a+1;
	}

对于上述函数中的第4行代码，一般人理解处理器会一次就执行完这条简单的语句，但实际情况并不是这样。我们可以用GCC编译出上述函数的汇编码：

.. code-block:: shell
    :linenos:

    $ riscv64-unknown-elf-gcc -o f.s -S f.c


可以看到生成的汇编代码如下：

.. code-block:: asm
    :linenos:
    :emphasize-lines: 18-23

    //f.s
	  .text
	  .globl	a
	  .section	.sbss,"aw",@nobits
	  .align	2
	  .type	a, @object
	  .size	a, 4
	a:
	  .zero	4
	  .text
	  .align	1
	  .globl	f
	  .type	f, @function
	f:
	  addi	sp,sp,-16
	  sd	s0,8(sp)
	  addi	s0,sp,16
	  lui	a5,%hi(a)
	  lw	a5,%lo(a)(a5)
	  addiw	a5,a5,1
	  sext.w	a4,a5
	  lui	a5,%hi(a)
	  sw	a4,%lo(a)(a5)
	  nop
	  ld	s0,8(sp)
	  addi	sp,sp,16
	  jr	ra


.. chyyuu 可以给上面的汇编码添加注释???

从中可以看出，对于高级语言的一条简单语句（C代码的第4行，对全局变量进行读写），很可能是由多条汇编代码（汇编代码的第18~23行）组成。如果这个函数是多个线程要执行的函数，那么在上述汇编代码第18行到第23行中的各行之间，可能会发生中断，从而导致操作系统执行抢占式的线程调度和切换，就会得到不一样的结果。由于执行这段汇编代码（第18~23行））的多个线程在访问全局变量过程中可能导致竞争状态，因此我们将此段代码称为临界区（critical section）。临界区是访问共享变量（或共享资源）的代码片段，不能由多个线程同时执行，即需要保证互斥。

下面是有两个线程T0、T1在一个时间段内的一种可能的执行情况：


=====  =====  =======   =======   ===========   =========
时间     T0     T1        OS        共享变量a      寄存器a5
=====  =====  =======   =======   ===========   =========
1       L18      --       --         0          a的高位地址
2       --      --      切换         0              0
3       --      L18       --         0          a的高位地址
4       L20      --       --         0              1
5       --      --      切换         0           a的高位地址
6       --      L20       --         0              1
7       --      --      切换         0              1
8       L23     --       --         1              1
9       --      --      切换         1              1
10      --      L23      --          1             1
=====  =====  =======   =======   ===========   =========

一般情况下，线程T0执行完毕后，再执行线程T1，那么共享全局变量``a``的值为 2 。但在上面的执行过程中，可以看到在线程执行指令的过程中会发生线程切换，这样在时刻10的时候，共享全局变量``a``的值为 1，这不是我们预期的结果。出现这种情况的原因是两个线程在操作系统的调度下（在哪个时刻调度具有不确定性），交错执行 ``a=a+1`` 的不同汇编指令序列，导致虽然增加全局变量 ``a`` 的代码被执行了两次，但结果还是只增加了1。这种多线程的最终执行结果不确定（indeterminate），取决于由于调度导致的不确定指令执行序列的情况就是竞态条件（race condition）。

如果每个线程在执行 ``a=a+1`` 这个C语句所对应多条汇编语句过程中，不会被操作系统切换，那么就不会出现多个线程交叉读写全局变量的情况，也就不会出现结果不确定的问题了。

所以，访问（特指写操作）共享变量代码片段，不能由多个线程同时执行（即并行）或者在一个时间段内都去执行（即并发）。要做到这一点，需要互斥机制的保障。从某种角度上看，这种互斥性也是一种原子性，即线程在临界区的执行过程中，不会出现只执行了一部分，就被打断并切换到其他线程执行的情况。即，要么线程执行的这一系列操作/指令都完成，要么这一系列操作/指令都不做，不会出现指令序列执行中被打断的情况。



锁的基本思路
-----------------------------------------

要保证多线程并发执行中的临界区的代码具有互斥性或原子性，我们可以建立一种锁，只有拿到锁的线程才能在临界区中执行。这里的锁与现实生活中的锁的含义很类似。比如，我们可以写出如下的伪代码：

.. code-block:: Rust
    :linenos:

    lock(mutex);    // 尝试取锁
    a=a+1;          // 临界区，访问临界资源 a
    unlock(mutex);  // 是否锁
    ...             // 剩余区

对于一个应用程序而言，它的执行是受到其执行环境的管理和限制的，而执行环境的主要组成就是用户态的系统库、操作系统和更底层的处理器，这说明我们需要有硬件和操作系统来对互斥进行支持。一个自然的想法是，这个 ``lock/unlock`` 互斥操作就是CPU提供的机器指令，那上面这一段程序就很容易在计算机上执行了。但需要注意，这里互斥的对象是线程的临界区代码，而临界区代码可以访问各种共享变量（简称临界资源）。只靠两条机器指令，难以识别各种共享变量，不太可能约束可能在临界区的各种指令执行共享变量操作的互斥性。所以，我们还是需要有一些相对更灵活和复杂一点的方法，能够设置一种所有线程能看到的标记，在一个能进入临界区的线程设置好这个标记后，其他线程都不能再进入临界区了。总体上看，对临界区的访问过程分为四个部分：

   1. 尝试取锁:查看锁是否可用，即临界区是否可访问（看占用临界区标志是否被设置），如果可以访问，则设置占用临界区标志（锁不可用）并转到步骤2，否则线程忙等或被阻塞;
   2. 临界区:访问临界资源的系列操作
   3. 释放锁:清除占用临界区标志（锁可用），如果有线程被阻塞，会唤醒阻塞线程；
   4. 剩余区：与临界区不相关部分的代码

根据上面的步骤，可以看到锁机制有两种：让线程忙等的忙等锁（spin lock），已经让线程阻塞的睡眠锁（sleep lock）。接下来，我们会基于用户态软件级、机器指令硬件级、内核态操作系统级三类方法来实现支持互斥的锁。

这里，我们还需要知道如何评价各种锁实现的效果。一般我们需要关注锁的三种属性：

1. 互斥性（mutual exclusion），即锁是否能够有效阻止多个线程进入临界区，这是最基本的属性。
2. 公平性（fairness），当锁可用时，每个竞争线程是否有公平的机会抢到锁。
3. 性能（performance），即使用锁的时间开销。

用户态软件级方法实现锁
------------------------------------------

我们可以快速想到的一个很朴素的锁的实现，用一个变量来表示锁的状态：已占用临界区 -- 1，未占用临界区 -- 0 ，然后根据这个变量的值来判断是否能进入临界区执行，伪代码如下：


.. code-block:: Rust
    :linenos:

    static mut mutex :i32 = 0;

    fn lock(mutex: i32) {
    	while (mutex);
    	mutex = 1;
    }
    
    fn unlock(mutex: i32){
    	mutex = 0;
    }
    

这样的锁实现是否能保证线程在临界区执行的互斥性呢？这里我们要注意到 ``mutex`` 其实也是一个全局共享变量，它也会把多个线程访问，在多个线程执行 ``lock`` 函数的时候，其实不能保证 ``lock`` 函数本身的互斥性。这就会带来问题，下面是一种可能的两线程在 ``lock`` 函数中的执行序列：

=====  ==============  ===============   =======   ==============
时间     T0                T1               OS        共享变量mutex   
=====  ==============  ===============   =======   ==============
1       L4               --                 --         0          
2       --               --                切换         0             
3       --               L4                 --         0         
4       --               --                切换         0            
5       L5(赋值1之前)      --                --         0           
6       --               --                切换         0            
7       --              L5(赋值1之前)        --         0           
8       --              --                切换         0              
9       L5(赋值1之后)     --                 --        1              
10      --              --                 切换          1
11      --              L5(赋值1之后)        --         1             
=====  ==============  ===============   =======   ==============

这样到第11步，两个线程都能够继续执行，并进入临界区，我们期望的互斥性并没有达到。那我们能否为 ``mutex`` 这个变量加上一种锁的互斥保护呢？如果这样做，我们将进入一个无限互斥保护的怪圈。要打破这种僵局，需要再思考一下，在用户态用软件方法实现锁，单靠一个 ``mutex`` 变量无法阻止线程在操作系统任意调度的情况下，越过 ``while`` 这个阻挡的判断循环。我们需要新的全局变量来帮忙：

.. code-block:: Rust
    :linenos:
  
    static mut flag : [i32;2] = [0,0]; // 哪个线程想拿到锁？
    static mut turn : i32 = 0;         // 排号：轮到哪个线程? (线程 0 or 1?)
　
    fn lock() {
        flag[self] = 1;             // 设置自己想取锁 self: 线程 ID
        turn = 1 - self;            // 设置另外一个线程先排号
        while ((flag[1-self] == 1) && (turn == 1 - self)); // 忙等
    }

    fn unlock() {
        flag[self] = 0;             // 设置自己放弃锁
    }

变量 turn 表示哪个线程可以进入临界区。即如果 turn == i，那么线程 Ti 允许在临界区内执行。数组 flag[i] 表示哪个线程准备进入临界区。例如，如果 flag[i] 为 1，那么线程 Ti 准备进入临界区，否则表示线程 Ti 不打算进入临界区。


为了进入临界区，线程 Ti 首先设置 flag[i] 的值为 1 ；并且设置 turn 的值为 j，从而表示如果另一个线程 Tj 希望进入临界区，那么 Tj 能够进入。如果两个线程同时试图进入，那么 turn 会几乎在同时设置成 i 或 j。但只有一个赋值语句的结果会保持；另一个也会设置，但会立即被重写。变量 turn 的最终值决定了哪个线程允许先进入临界区。


这里是如何保证互斥的呢？仔细分析代码，可注意到：

1. 只有当 flag[j] == 0 或者 turn == i 时，线程 Ti 才能进入临界区。
2. 如果两个线程同时在临界区内执行，那么 flag[0]==flag[1]==true。

这意味着线程T0 和 T1 不可能同时成功地执行它们的 while 语句，因为 turn 的值只可能为 0 或 1，而不可能同时为两个值。因此，如果turn的值为j, 那么只有一个线程 Tj 能成功跳出 while 语句，而另外一个线程 Ti 不得不再次陷入判断（“turn == j”）的循环而无法跳出。最终结果是，只要在临界区内，flag[j]==true 和 turn==j 就同时成立。这就保证了只有一个线程能进入临界区的互斥性。


机器指令硬件级方法实现锁
-----------------------------------------



实现锁：原子指令
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


实现锁：链接的加载和条件式存储指令
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



内核态操作系统级方法实现锁
-----------------------------------------

实现锁：Mutex系统调用
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~